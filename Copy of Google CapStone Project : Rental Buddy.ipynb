{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.7"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/chinthamsreeraj/google-capstone-project-rental-buddy.e1fa31ae-daee-439b-b6e6-600775254d2a.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250706/auto/storage/goog4_request&X-Goog-Date=20250706T030023Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0fab2f0324dfe51a4a178c190604cb5a00476967aff50e00d1aecc5aa1bc004f9171d5ab8ebb2a2185732f37ecf66fa94d7dc4be6c6610eb46b01496d442b29bc851e587cca0c282316f1063dd0c8063bef36e2b3c1acf3430dec895111f33e67a1918716bdbba68fef70037e730b5023dff654dfe0ed918433e85780615cab52e469c5a643bccbef77151f7c2c82501c7067637ce77307518a36f0374201026ba7c8a1f647f85c1c2860afd795f7691a2bdc80dad80162cdcba95548300b078cc155a1516630e8403d57d62d103c5ea777ce22db6bc67769f505a72fc7fca8b5375ed2204d07c5305aca1d24a96ef271be1da048a7c66d7d01cd3635e7369e9","timestamp":1751771008356}],"name":"Google CapStone Project : Rental Buddy"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11495126,"sourceType":"datasetVersion","datasetId":7205980}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":0,"nbformat":4,"cells":[{"source":["# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n","# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n","import kagglehub\n","kagglehub.login()\n"],"metadata":{"id":"ibcgUcaRrrNT"},"cell_type":"code","outputs":[],"execution_count":null},{"source":["# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","\n","chinthamsreeraj_rental_10k_dataset_path = kagglehub.dataset_download('chinthamsreeraj/rental-10k-dataset')\n","\n","print('Data source import complete.')\n"],"metadata":{"id":"HHdYyIr_rrNU"},"cell_type":"code","outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Initial Setup: Installing Required Packages\n","\n","This cell installs the necessary Python packages for the project using `pip`. The packages include:\n","\n","- **chromadb**: A vector database for storing and querying embeddings, used to store property listings.\n","- **google-generativeai**: Google's Generative AI SDK for embedding generation and content creation.\n","- **google-api-core**: Core utilities for interacting with Google APIs.\n","- **langchain**: A framework for building applications with LLMs, used for chaining LLM interactions.\n","- **langchain-google-genai**: LangChain integration for Google's Generative AI models.\n","- **langgraph**: A library for building stateful, graph-based workflows with LangChain.\n","- **pydantic**: For data validation and serialization, used to define structured property data models.\n","- **scikit-learn**: For machine learning tasks, specifically KMeans clustering for grouping properties.\n","- **typing-extensions**: For enhanced type hints, supporting advanced typing features."],"metadata":{"id":"3DiPNx_krrNU"}},{"cell_type":"code","source":["!pip install chromadb google-generativeai google-api-core langchain langchain-google-genai langgraph pydantic scikit-learn typing-extensions"],"metadata":{"id":"9Xy1WNvnFlXo"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Importing Libraries and Defining Constants\n","\n","This cell imports the required libraries and modules for the project and sets up key constants:\n","\n","- **Libraries**:\n","  - `os`, `json`, `warnings`: For file handling, JSON processing, and warning suppression.\n","  - `pandas`, `numpy`: For data manipulation and numerical computations.\n","  - `google.genai`: For interacting with Google's Generative AI models (e.g., embeddings).\n","  - `chromadb`: For vector database operations.\n","  - `langchain_core`, `langchain_google_genai`, `langgraph`: For building conversational workflows with LLMs.\n","  - `pydantic`: For defining structured data models with validation.\n","  - `sklearn`: For KMeans clustering and data scaling.\n","  - `typing`: For type hints to ensure code robustness.\n","\n","- **Constants**:\n","  - `GOOGLE_API_KEY`: The API key for accessing Google's Generative AI services (hardcoded here, though ideally should be stored securely).\n","  - `DATA_URL`: Path to the dataset (`apartments_for_rent_classified_10K.csv`), containing rental listings.\n","  - `COLLECTION_NAME`: Name of the ChromaDB collection (`Rental_Listings`) for storing property embeddings.\n","  - `EMBEDDING_MODEL`: Specifies the Google embedding model (`text-embedding-004`) for generating text embeddings.\n","\n","These imports and constants set the foundation for data processing, embedding generation, vector storage, and conversational workflows."],"metadata":{"id":"rptld16TrrNV"}},{"cell_type":"code","source":["import os\n","import json\n","import warnings\n","from typing import List, Dict, Annotated, Literal, Optional\n","import pandas as pd\n","import numpy as np\n","from google.genai import types\n","from chromadb import Documents, EmbeddingFunction, Embeddings\n","from google.api_core import retry\n","from google import genai\n","import chromadb\n","from chromadb import Documents, EmbeddingFunction, Embeddings\n","\n","from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, ToolMessage\n","from langchain_core.tools import tool\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.graph.message import add_messages\n","from langgraph.prebuilt import ToolNode\n","\n","from pydantic import BaseModel, Field, ValidationError\n","from typing_extensions import TypedDict\n","\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n","DATA_URL = '/kaggle/input/rental-10k-dataset/apartments_for_rent_classified_10K.csv'\n","\n","COLLECTION_NAME = \"Rental_Listings\"\n","EMBEDDING_MODEL = \"models/text-embedding-004\""],"metadata":{"id":"3ceQUvsFFhwI"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Loading and Cleaning the Rental Dataset\n","\n","This cell loads the rental dataset from a CSV file and performs initial data cleaning:\n","\n","- **Loading Data**:\n","  - The dataset (`apartments_for_rent_classified_10K.csv`) is read into a Pandas DataFrame using `pd.read_csv`. The file uses a semicolon (`;`) as the separator and `cp1252` encoding.\n","  - The dataset contains 10,000 rows and 22 columns, including property details like `id`, `title`, `price`, `bedrooms`, `cityname`, and `state`.\n","\n","- **Cleaning Steps**:\n","  - Strips whitespace from column names to ensure consistency.\n","  - Drops rows with missing values using `dropna()`, reducing the dataset to 2,570 rows where all essential fields are present.\n","  - Drops unnecessary columns (`category`, `has_photo`, `time`) to focus on relevant features, resulting in 19 columns.\n","  - Prints the DataFrame's shape, columns, and a preview of the data at each step for verification.\n","\n","- **Output**:\n","  - Initial shape: (10,000, 22)\n","  - After dropping missing values: (2,570, 22)\n","  - After dropping columns: (2,570, 19)\n","  - The cleaned DataFrame includes key fields like `id`, `title`, `price`, `bedrooms`, `bathrooms`, `cityname`, and `state`, ready for embedding and querying.\n","\n","This step ensures the dataset is clean and structured for downstream tasks like embedding generation and vector storage."],"metadata":{"id":"zohxqJ5rrrNW"}},{"cell_type":"code","source":["print(f\"Loading data from: {DATA_URL}\")\n","df = pd.read_csv(DATA_URL, sep=\";\", encoding='cp1252')\n","print(f\"Loaded {len(df)} rows of data.\")\n","print(\"Initial DataFrame shape:\", df.shape)\n","print(\"Initial DataFrame columns (before cleaning):\", df.columns.tolist())\n","df.columns = df.columns.str.strip()\n","print(\"Initial DataFrame columns (after stripping whitespace):\", df.columns.tolist())\n","print(\"Initial DataFrame head:\\n\", df.head())\n","df_clean = df.dropna()\n","print(\"\\nShape after dropping rows with missing essential data:\", df_clean.shape)\n","columns_to_drop = ['category', 'has_photo', 'time']\n","df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')\n","print(\"Shape after dropping other columns:\", df_clean.shape)\n","print(\"Cleaned DataFrame head:\\n\", df_clean.head())"],"metadata":{"id":"ZrTGnsx_F5ev"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Setting Up ChromaDB and Embedding Property Listings\n","\n","This cell initializes the Google Generative AI client, defines a custom embedding function, and stores the cleaned property listings in a ChromaDB vector database:\n","\n","- **Google Client Initialization**:\n","  - A `genai.Client` is created using the `GOOGLE_API_KEY`.\n","  - Lists available models that support the `embedContent` action, confirming that `text-embedding-004` (used for embeddings) is available.\n","\n","- **Custom Embedding Function**:\n","  - Defines `GeminiEmbeddingFunction`, a custom `EmbeddingFunction` for ChromaDB that uses Google's `text-embedding-004` model.\n","  - Supports retry logic for transient API errors (e.g., rate limits or server issues) using `google.api_core.retry`.\n","  - Configures the embedding task as `retrieval_document` for document embeddings (can switch to `retrieval_query` for queries).\n","  - Returns embeddings as a list of float vectors.\n","\n","- **ChromaDB Setup**:\n","  - Initializes a ChromaDB client and creates/gets a collection named `Rental_Listings`.\n","  - Converts each row of the cleaned DataFrame to JSON strings (`documents`), uses DataFrame indices as `ids`, and stores metadata as dictionaries.\n","  - Processes the data in batches (size=100) to avoid overwhelming the API, adding documents, IDs, and metadata to the collection.\n","  - Embeds the JSON strings using the `GeminiEmbeddingFunction` and stores them in the vector database.\n","\n","- **Output**:\n","  - Successfully creates the `Rental_Listings` collection with 2,570 documents.\n","  - A deprecation warning is noted for `GeminiEmbeddingFunction` due to missing `__init__`, but it does not affect functionality.\n","\n","This step prepares the property listings for semantic search by embedding them into a vector space and storing them in ChromaDB."],"metadata":{"id":"CK1V2jG2rrNW"}},{"cell_type":"code","source":["client = genai.Client(api_key=GOOGLE_API_KEY)\n","\n","for m in client.models.list():\n","    if \"embedContent\" in m.supported_actions:\n","        print(m.name)\n","\n","\n","is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n","\n","\n","class GeminiEmbeddingFunction(EmbeddingFunction):\n","    document_mode = True\n","\n","    @retry.Retry(predicate=is_retriable)\n","    def __call__(self, input: Documents) -> Embeddings:\n","        if self.document_mode:\n","            embedding_task = \"retrieval_document\"\n","        else:\n","            embedding_task = \"retrieval_query\"\n","\n","        response = client.models.embed_content(\n","            model=\"models/text-embedding-004\",\n","            contents=input,\n","            config=types.EmbedContentConfig(\n","                task_type=embedding_task,\n","            ),\n","        )\n","        return [e.values for e in response.embeddings]\n","\n","def batch_list(lst, batch_size):\n","    for i in range(0, len(lst), batch_size):\n","        yield lst[i:i + batch_size]\n","\n","embed_fn = GeminiEmbeddingFunction()\n","embed_fn.document_mode = True\n","\n","chroma_client = chromadb.Client()\n","\n","documents = df_clean.apply(lambda row: row.to_json(), axis=1).tolist()\n","ids = df_clean.index.astype(str).tolist()\n","metadatas = df_clean.to_dict(orient='records')\n","collection_name = \"Rental_Listings\"\n","collection = chroma_client.get_or_create_collection(name=collection_name, embedding_function=embed_fn)\n","batch_size = 100\n","total_docs = len(documents)\n","for batch_docs, batch_ids, batch_metas in zip(\n","    batch_list(documents, batch_size),\n","    batch_list(ids, batch_size),\n","    batch_list(metadatas, batch_size)):\n","    collection.add(documents=batch_docs, ids=batch_ids, metadatas=batch_metas)\n","\n","print(f\"Created collection '{collection_name}' with {total_docs} documents.\")"],"metadata":{"id":"Wnc2VOahGj-S"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Testing ChromaDB Query Functionality\n","\n","This cell tests the ChromaDB setup by performing a sample query to retrieve properties:\n","\n","- **Query Setup**:\n","  - Queries for \"I want 5 properties from Illinois\" using the `GeminiEmbeddingFunction` to generate an embedding for the query text.\n","  - Searches the `Rental_Listings` collection for the top 5 matching documents based on embedding similarity.\n","\n","- **Query Execution**:\n","  - Uses `collection.query` with the query embedding, requesting 5 results and including `documents` and `metadatas`.\n","  - Iterates through the results, printing each property's ID, a preview of the document text (first 150 characters), and key metadata (`cityname`, `state`, `price`).\n","\n","- **Output**:\n","  - Retrieves 5 properties, all from Chicago, IL, with prices ranging from $1,755 to $3,675.\n","  - Each result includes the document ID, a snippet of the JSON document, and metadata, confirming that the vector database is functioning correctly.\n","\n","This test validates that the embeddings and ChromaDB collection are set up correctly, allowing semantic searches based on natural language queries."],"metadata":{"id":"fx8iecOxrrNX"}},{"cell_type":"code","source":["print(\"\\n--- Running initial ChromaDB query test ---\")\n","query_text = \"I want 5 properties from Illinois\"\n","query_embedding = embed_fn([query_text])[0]\n","print(f\"Generated query embedding for: '{query_text}'\")\n","test_results = collection.query(\n","        query_embeddings=[query_embedding],\n","        n_results=5,\n","        include=['documents', 'metadatas']\n","    )\n","\n","print(\"\\nTest Query Results:\")\n","if test_results and test_results.get(\"ids\") and test_results[\"ids\"][0]:\n","      for i, doc_id in enumerate(test_results[\"ids\"][0]):\n","          metadata = test_results[\"metadatas\"][0][i]\n","          document_text = test_results[\"documents\"][0][i]\n","          print(f\"Result {i+1} (ID: {doc_id}):\")\n","          doc_snippet = str(document_text)\n","          print(f\"  Document Text Preview: {doc_snippet[:150]}...\")\n","          print(f\"  Metadata (City, State, Price): {metadata.get('cityname')}, {metadata.get('state')}, ${metadata.get('price')}\")\n","          print(\"-\" * 10)\n","else:\n","  print(\"No results found for the test query.\")"],"metadata":{"id":"UNhFD7KkIO4S"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining Data Models and Graph State\n","\n","This cell defines the data structures and state for the LangGraph workflow:\n","\n","- **PropertyJson (Pydantic Model)**:\n","  - A `BaseModel` defining the structure of a property with fields like `id`, `title`, `price`, `bedrooms`, `bathrooms`, `city`, `state`, etc.\n","  - Uses `Optional` for fields that may be missing and includes descriptions for clarity.\n","  - Ensures data validation when properties are added to the state.\n","\n","- **TripDict (TypedDict)**:\n","  - Defines a trip as a dictionary with:\n","    - `properties`: A list of `PropertyJson` objects.\n","    - `map_url`: A string for the Google Maps URL (to be populated later).\n","    - `summary_card`: A dictionary summarizing the trip's properties.\n","\n","- **Pstate (TypedDict)**:\n","  - The state for the LangGraph workflow, containing:\n","    - `messages`: A list of `BaseMessage` objects (e.g., `HumanMessage`, `AIMessage`) for conversation history, annotated with `add_messages` to append new messages.\n","    - `property_set`: A list of `PropertyJson` objects representing the user's selected properties.\n","    - `trips`: A list of `TripDict` objects for visit planning.\n","\n","- **Global Variables**:\n","  - `GLOBAL_COLLECTION`: Stores the ChromaDB collection for querying.\n","  - `GLOBAL_QUERY_EMBED_FN`: Stores the embedding function for queries.\n","  - `GLOBAL_PROPERTY_LIST_SIZE` and `GLOBAL_TRIP_SIZE`: Initialized to 0 (though not used in the provided code).\n","\n","These structures ensure that property data, conversation history, and trip plans are managed consistently throughout the workflow."],"metadata":{"id":"m46E8jsCrrNX"}},{"cell_type":"code","source":["class PropertyJson(BaseModel):\n","    id: str = Field(description=\"Unique identifier for the property (from dataset)\")\n","    title: Optional[str] = Field(None, description=\"Title of the listing\")\n","    description: Optional[str] = Field(None, description=\"Full description of the property\")\n","    price: Optional[int] = Field(None, description=\"Rental price (integer)\")\n","    bedrooms: Optional[int] = Field(None, description=\"Number of bedrooms\")\n","    bathrooms: Optional[int] = Field(None, description=\"Number of bathrooms\")\n","    property_type: Optional[str] = Field(None, description=\"Type of property (e.g., apartment, house)\")\n","    amenities: Optional[str] = Field(None, description=\"List of amenities (comma-separated string or 'None')\")\n","    address: Optional[str] = Field(None, description=\"Street address\")\n","    city: Optional[str] = Field(None, description=\"City\")\n","    state: Optional[str] = Field(None, description=\"State\")\n","    latitude: Optional[float] = Field(None, description=\"Latitude coordinate\")\n","    longitude: Optional[float] = Field(None, description=\"Longitude coordinate\")\n","    pets_allowed: Optional[str] = Field(None, description=\"Pet policy\")\n","    sqft: Optional[float] = Field(None, description=\"Square footage\")\n","\n","\n","class TripDict(TypedDict):\n","    properties: List[PropertyJson]\n","    map_url: str\n","    summary_card: Dict\n","\n","class Pstate(TypedDict):\n","    messages: Annotated[List[BaseMessage], add_messages]\n","    property_set: List[PropertyJson]\n","    trips: List[TripDict]\n","\n","GLOBAL_COLLECTION = collection\n","GLOBAL_QUERY_EMBED_FN = embed_fn\n","GLOBAL_PROPERTY_LIST_SIZE = 0\n","GLOBAL_TRIP_SIZE = 0"],"metadata":{"id":"SgFIi9_CWG-5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining the `query_properties` Tool\n","\n","This cell defines a LangChain tool (`query_properties`) for searching the ChromaDB vector database:\n","\n","- **Purpose**:\n","  - Queries the `Rental_Listings` collection for properties matching a natural language description (e.g., \"2 bedroom apartment in Chicago under $2000 with parking\").\n","  - Returns up to `n_results` matching properties as a list of dictionaries.\n","\n","- **Implementation**:\n","  - Takes a `requirements` string and `n_results` (default=5) as inputs.\n","  - Uses `GLOBAL_QUERY_EMBED_FN` to generate an embedding for the query text.\n","  - Queries the ChromaDB collection with the embedding, retrieving `metadatas` and `documents`.\n","  - Processes results, extracting metadata and adding the document ID to each property dictionary.\n","  - Includes error handling for:\n","    - Missing global collection or embedding function.\n","    - Invalid or zero query embeddings.\n","    - Missing or non-dictionary metadata.\n","    - General exceptions during querying.\n","\n","- **Output**:\n","  - Returns a list of property dictionaries (with metadata and ID) if successful, or an empty list if no results or errors occur.\n","  - Logs detailed debugging information (e.g., number of properties found, errors).\n","\n","This tool enables semantic search, allowing users to find properties based on natural language descriptions."],"metadata":{"id":"g2tci4vLrrNX"}},{"cell_type":"code","source":["@tool\n","def query_properties(requirements: str, n_results: int = 5) -> List[dict]:\n","    \"\"\"\n","    Query the vector database for properties matching the given requirements description.\n","    Args:\n","        requirements: A natural language string describing the desired property features (e.g., '2 bedroom apartment in Chicago under $2000 with parking').\n","        n_results: The maximum number of properties to return.\n","    Returns:\n","        A list of dictionaries, where each dictionary represents a property matching the query. Includes metadata and the document ID. Returns an empty list if no matches found or an error occurs.\n","    \"\"\"\n","    print(f\"\\n--- Tool: query_properties ---\")\n","    print(f\"Requirements: '{requirements}', n_results: {n_results}\")\n","    if GLOBAL_COLLECTION is None or GLOBAL_QUERY_EMBED_FN is None:\n","         print(\"--- Tool Error: GLOBAL_COLLECTION or GLOBAL_QUERY_EMBED_FN not available. ---\")\n","         return []\n","\n","    try:\n","        query_embedding = GLOBAL_QUERY_EMBED_FN([requirements])[0]\n","        if not query_embedding or all(v == 0.0 for v in query_embedding):\n","             print(\"--- Tool Error: Failed to generate query embedding (might be empty or zero vector). ---\")\n","             return []\n","\n","        results = GLOBAL_COLLECTION.query(\n","            query_embeddings=[query_embedding],\n","            n_results=n_results,\n","            include=['metadatas', 'documents']\n","        )\n","\n","        properties = []\n","        if results and results.get('ids') and results.get('ids')[0]:\n","             ids_list = results['ids'][0]\n","             metadatas_list = results.get('metadatas', [None])[0]\n","             documents_list = results.get('documents', [None])[0]\n","\n","             for i, prop_id in enumerate(ids_list):\n","                 meta = metadatas_list[i] if metadatas_list and i < len(metadatas_list) else {}\n","                 if not isinstance(meta, dict):\n","                     print(f\"--- Tool Warning: Skipping result ID {prop_id} due to missing or non-dictionary metadata. ---\")\n","                     continue\n","\n","                 prop_dict = meta.copy()\n","                 prop_dict['id'] = prop_id\n","                 properties.append(prop_dict)\n","\n","             print(f\"--- Tool: query_properties found {len(properties)} properties. ---\")\n","             return properties\n","        else:\n","            print(\"--- Tool: query_properties found no results or unexpected result format. ---\")\n","            return []\n","    except Exception as e:\n","        print(f\"--- Tool Error in query_properties: {e} ---\")\n","        return []"],"metadata":{"id":"_Bc4qzpgXWxt"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining the `add_to_property_set` Tool\n","\n","This cell defines a LangChain tool (`add_to_property_set`) for adding properties to the user's working set:\n","\n","- **Purpose**:\n","  - Adds properties (as dictionaries) to the `property_set` in the graph state, ensuring no duplicates based on `id`.\n","  - Validates properties using the `PropertyJson` Pydantic model.\n","\n","- **Implementation**:\n","  - Takes a list of property dictionaries (`properties_to_add`) and the current state (`state`) as inputs.\n","  - Checks if `property_set` exists in the state; initializes it as an empty list if not.\n","  - Tracks existing property IDs to prevent duplicates.\n","  - Iterates through input properties, validating each with `PropertyJson`:\n","    - Skips non-dictionary items or those without an `id`.\n","    - Converts valid dictionaries to `PropertyJson` objects and adds them to the set.\n","    - Logs warnings for validation errors or missing IDs.\n","  - Updates the state with the new properties and logs the number added.\n","\n","- **Output**:\n","  - Returns the updated state with the expanded `property_set`.\n","  - Provides detailed logging (e.g., number of properties added, validation errors).\n","\n","This tool allows users to save properties they are interested in, ensuring data integrity through validation."],"metadata":{"id":"-QKUBxWmrrNY"}},{"cell_type":"code","source":["@tool\n","def add_to_property_set(properties_to_add: List[Dict], state: Pstate) -> Pstate:\n","    \"\"\"\n","    Adds one or more properties (provided as dictionaries) to the\n","    user's working property set.\n","    Filters out properties already present based on their 'id'.\n","    Converts valid dicts to PropertyJson objects.\n","    Args:\n","        properties_to_add: A list of dictionaries, each representing a\n","            property. Must contain necessary fields for PropertyJson.\n","        state: The current graph state.\n","    Returns:\n","        The updated graph state with properties added to the\n","        property_set.\n","    \"\"\"\n","    print(f\"\\n--- Tool: add_to_property_set ---\")\n","    print(f\"Attempting to add {len(properties_to_add)} properties.\")\n","\n","    if 'property_set' not in state or not isinstance(state['property_set'], list):\n","        print(\"--- Tool Warning: 'property_set' not found or not a list in state. Initializing as empty list. ---\")\n","        state['property_set'] = []\n","\n","    current_ids = {p.id for p in state['property_set']}\n","    added_count = 0\n","    new_properties_validated: List[PropertyJson] = []\n","\n","    if not isinstance(properties_to_add, list):\n","        print(f\"--- Tool Warning: Input 'properties_to_add' is not a list ({type(properties_to_add)}). Skipping. ---\")\n","        return state\n","\n","    for prop_dict in properties_to_add:\n","        if not isinstance(prop_dict, dict):\n","            print(f\"--- Tool Warning: Skipping item that is not a dictionary: {prop_dict} ---\")\n","            continue\n","\n","        prop_id = prop_dict.get('id')\n","        if not prop_id:\n","            print(f\"--- Tool Warning: Skipping property due to missing or empty 'id': {prop_dict.get('title', 'N/A')} ---\")\n","            continue\n","\n","        if prop_id not in current_ids:\n","            try:\n","                validated_prop = PropertyJson(**prop_dict)\n","                new_properties_validated.append(validated_prop)\n","                current_ids.add(prop_id)\n","                added_count += 1\n","            except ValidationError as e:\n","                print(f\"--- Tool Warning: Skipping property ID {prop_id} ('{prop_dict.get('title', 'N/A')}') due to Pydantic validation error: {e} ---\")\n","            except Exception as e:\n","                 print(f\"--- Tool Warning: Skipping property ID {prop_id} ('{prop_dict.get('title', 'N/A')}') due to unexpected error during validation: {e} ---\")\n","\n","    state['property_set'].extend(new_properties_validated)\n","    print(f\"--- Tool: Added {added_count} new properties. Property set size: {len(state['property_set'])} ---\")\n","\n","    return state"],"metadata":{"id":"j6qSRxOXZuMI"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining the `remove_from_property_set` Tool\n","\n","This cell defines a LangChain tool (`remove_from_property_set`) for removing properties from the user's working set:\n","\n","- **Purpose**:\n","  - Removes properties from the `property_set` based on their 0-based indices.\n","  - Ensures only valid indices are processed to prevent errors.\n","\n","- **Implementation**:\n","  - Takes a list of indices (`indices_to_remove`) and the current state (`state`) as inputs.\n","  - Checks if `property_set` exists and is non-empty; returns the state unchanged if not.\n","  - Filters and sorts valid indices (integers within the range of `property_set` length) in reverse order to avoid index shifting during removal.\n","  - Removes properties at the specified indices, tracking removed properties and their IDs.\n","  - Updates the state and logs the number of properties removed and their IDs.\n","\n","- **Output**:\n","  - Returns the updated state with the reduced `property_set`.\n","  - Provides detailed logging (e.g., indices removed, property IDs, warnings for invalid indices).\n","\n","This tool allows users to refine their property set by removing unwanted properties."],"metadata":{"id":"6RRJsU0NrrNY"}},{"cell_type":"code","source":["@tool\n","def remove_from_property_set(indices_to_remove: List[int], state: Pstate) -> Pstate:\n","    \"\"\"\n","    Removes properties from the working set based on their list index (0-based).\n","    Args:\n","        indices_to_remove: A list of integer indices of the properties\n","            to remove from the current property_set.\n","        state: The current graph state.\n","    Returns:\n","        The updated graph state with specified properties removed.\n","    \"\"\"\n","    print(f\"\\n--- Tool: remove_from_property_set ---\")\n","    print(f\"Attempting to remove properties at indices: {indices_to_remove}\")\n","\n","    if 'property_set' not in state or not isinstance(state['property_set'], list) or not state['property_set']:\n","        print(\"--- Tool Warning: Cannot remove properties, property set is empty or invalid. ---\")\n","        return state\n","\n","    initial_count = len(state['property_set'])\n","    valid_indices = sorted(\n","        [idx for idx in indices_to_remove if isinstance(idx, int) and 0 <= idx < initial_count],\n","        reverse=True\n","    )\n","\n","    if not valid_indices:\n","        print(f\"--- Tool Warning: No valid indices provided to remove. Indices provided: {indices_to_remove}. Set size: {initial_count}. ---\")\n","        return state\n","\n","    removed_count = 0\n","    removed_props = []\n","    properties_after_removal = list(state['property_set'])\n","\n","    for idx in valid_indices:\n","        if 0 <= idx < len(properties_after_removal):\n","             removed_props.append(properties_after_removal.pop(idx))\n","             removed_count += 1\n","\n","\n","    state['property_set'] = properties_after_removal\n","    print(f\"--- Tool: Removed {removed_count} properties. Property set size: {len(state['property_set'])} ---\")\n","\n","    if removed_props:\n","        removed_ids = [p.id for p in removed_props if p.id]\n","        if removed_ids:\n","            print(f\"--- Tool: Removed property IDs: {', '.join(removed_ids)} ---\")\n","        else:\n","            print(f\"--- Tool: Removed properties but they had no IDs. ---\")\n","\n","    return state"],"metadata":{"id":"TNzWfbMRavKr"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining the `generate_groups_for_visits` Tool\n","\n","This cell defines a LangChain tool (`generate_groups_for_visits`) for clustering properties into visit groups:\n","\n","- **Purpose**:\n","  - Clusters properties in the `property_set` into `n_trips` groups based on geographic coordinates (latitude, longitude) using KMeans clustering.\n","  - Prepares properties for visit planning by grouping them logically by location.\n","\n","- **Implementation**:\n","  - Takes the desired number of trips (`n_trips`) and the current state (`state`) as inputs.\n","  - Validates the `property_set` and filters properties with valid coordinates.\n","  - Adjusts `n_trips` to be within valid bounds (1 to the number of valid properties).\n","  - Uses `StandardScaler` to normalize coordinates and `KMeans` to cluster properties into `n_trips` groups.\n","  - Sorts properties within each group by latitude and title for consistent ordering.\n","  - Creates `TripDict` entries with clustered properties, empty `map_url`, and empty `summary_card`.\n","  - Updates the state’s `trips` field with the new groups, clearing previous trips.\n","\n","- **Output**:\n","  - Returns the updated state with the `trips` field populated.\n","  - Includes extensive logging for debugging (e.g., number of clusters, properties processed, errors).\n","\n","This tool enables geographic organization of properties, making visit planning more efficient."],"metadata":{"id":"c7C7CevarrNY"}},{"cell_type":"code","source":["@tool\n","def generate_groups_for_visits(n_trips: int, state: Pstate) -> Pstate:\n","    \"\"\"\n","    Clusters properties currently in the property_set into a specified\n","    number of groups based on geographic coordinates (latitude, longitude)\n","    for visit planning.\n","    Args:\n","        n_trips: The desired number of visit groups (clusters).\n","        state: The current graph state containing the property_set.\n","    Returns:\n","        The updated graph state with the 'trips' field populated with\n","        initial trip groups (properties only). Clears previous trips.\n","    \"\"\"\n","    print(f\"\\n--- Tool: generate_groups_for_visits ---\")\n","    properties = state.get('property_set', [])\n","    print(f\"Attempting to generate {n_trips} visit groups from {len(properties)} properties.\")\n","\n","    if not isinstance(properties, list):\n","        print(\"--- Tool Warning: 'property_set' in state is not a list. Clearing trips and returning. ---\")\n","        state['trips'] = []\n","        return state\n","\n","    valid_properties = [p for p in properties if p.latitude is not None and p.longitude is not None]\n","\n","    if not valid_properties:\n","        print(\"--- Tool Warning: Cannot generate groups, no properties with valid coordinates in the set. Clearing trips. ---\")\n","        state['trips'] = []\n","        return state\n","    if not isinstance(n_trips, int) or n_trips <= 0:\n","        print(f\"--- Tool Warning: Invalid number of trips ({n_trips}). Must be a positive integer. Setting to 1. ---\")\n","        n_trips = 1\n","\n","    if n_trips > len(valid_properties):\n","        print(f\"--- Tool Warning: Number of trips ({n_trips}) > number of valid properties ({len(valid_properties)}). Setting n_trips = {len(valid_properties)}. ---\")\n","        n_trips = len(valid_properties)\n","\n","    if n_trips == 0 and len(valid_properties) > 0:\n","         print(\"--- Tool Warning: Number of trips calculated as 0 but valid properties exist. Setting to 1. ---\")\n","         n_trips = 1\n","\n","    if n_trips == 0:\n","        print(\"--- Tool Warning: Number of trips is 0 after adjustments. No groups will be generated. ---\")\n","        state['trips'] = []\n","        return state\n","\n","    try:\n","        coords = np.array([[p.latitude, p.longitude] for p in valid_properties])\n","        scaler = StandardScaler()\n","        coords_scaled = scaler.fit_transform(coords)\n","\n","        n_clusters_actual = min(n_trips, len(coords_scaled))\n","\n","        if n_clusters_actual == 0:\n","            print(\"--- Tool Warning: Not enough samples for clustering (0). No groups generated. ---\")\n","            state['trips'] = []\n","            return state\n","\n","        print(f\"--- Tool: Running KMeans with {n_clusters_actual} clusters ---\")\n","        with warnings.catch_warnings():\n","            warnings.filterwarnings(\"ignore\", message=\"Number of distinct clusters\")\n","            kmeans = KMeans(n_clusters=n_clusters_actual, random_state=42, n_init='auto')\n","\n","        labels = kmeans.fit_predict(coords_scaled)\n","\n","        trips_temp: List[TripDict] = []\n","        for i in range(n_clusters_actual):\n","            group_properties = [valid_properties[j] for j, label in enumerate(labels) if label == i]\n","            if group_properties:\n","                 group_properties_sorted = sorted(group_properties,\n","                                                  key=lambda p: (p.latitude if p.latitude is not None else float('inf'),\n","                                                                 p.title if p.title is not None else ''))\n","                 trips_temp.append({\n","                     \"properties\": group_properties_sorted,\n","                     \"map_url\": \"\",\n","                     \"summary_card\": {}\n","                 })\n","\n","        state['trips'] = trips_temp\n","\n","        print(f\"--- Tool: Successfully generated {len(state['trips'])} trip groups. ---\")\n","\n","    except Exception as e:\n","        print(f\"--- Tool Error in generate_groups_for_visits: {e} ---\")\n","        state['trips'] = []\n","\n","    return state"],"metadata":{"id":"cJxYyrXAbGen"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining the `generate_visit_plan` Tool\n","\n","This cell defines a LangChain tool (`generate_visit_plan`) for creating visit plans with Google Maps URLs and summary cards:\n","\n","- **Purpose**:\n","  - Enhances the `trips` created by `generate_groups_for_visits` by generating Google Maps URLs and detailed summary cards for each trip.\n","  - Must be called after `generate_groups_for_visits`.\n","\n","- **Implementation**:\n","  - Takes the current state (`state`) as input and checks for valid `trips`.\n","  - Initializes a `genai.Client` for calling the `gemini-2.0-flash` model to generate map URLs.\n","  - For each trip:\n","    - Constructs a prompt with property details (title, address, city, state, bedrooms, bathrooms, sqft, price, pets, amenities).\n","    - Calls `gemini-2.0-flash` to generate a Google Maps URL showing property locations.\n","    - Validates the URL and sets `map_url` (or sets to \"N/A\" with an error message if invalid).\n","    - Creates a `summary_card` with:\n","      - Trip index, number of properties, cities covered, average/total price.\n","      - A preview of property details (up to 3) and full details in `_full_property_details`.\n","  - Handles errors (e.g., missing API key, invalid properties, LLM failures) with appropriate logging.\n","\n","- **Output**:\n","  - Returns the updated state with `map_url` and `summary_card` populated for each trip.\n","  - Provides detailed logging for each step (e.g., LLM calls, URL validation, summary card generation).\n","\n","This tool completes the visit planning process by providing actionable map links and comprehensive trip summaries."],"metadata":{"id":"fo9ffm-drrNY"}},{"cell_type":"code","source":["@tool\n","def generate_visit_plan(state: Pstate) -> Pstate:\n","    \"\"\"\n","    Generates Google Maps search URLs (using gemini-2.0-flash) showing\n","    property locations and comprehensive summary cards for each trip group\n","    previously created by 'generate_groups_for_visits'.\n","    Includes details like bedrooms, bathrooms, price, square footage,\n","    pets, and amenities in the prompt and summary.\n","    Must be called AFTER 'generate_groups_for_visits'.\n","    Args:\n","        state: The current graph state containing the 'trips' list.\n","    Returns:\n","        The updated graph state with 'map_url' and 'summary_card'\n","        populated for each trip.\n","    \"\"\"\n","    print(f\"\\n--- Tool: generate_visit_plan ---\")\n","    if not state.get('trips') or not isinstance(state['trips'], list):\n","        print(\"--- Tool Warning: No trips found or trips format incorrect. Run 'generate_groups_for_visits' first. ---\")\n","        state['trips'] = []\n","        return state\n","\n","    print(f\"Attempting to generate visit plans for {len(state['trips'])} trips.\")\n","\n","    client = None\n","    try:\n","        if 'GOOGLE_API_KEY' in globals():\n","             client = genai.Client(api_key=GOOGLE_API_KEY)\n","             print(\"--- Tool: Gemini client initialized. ---\")\n","             client_initialized = True\n","        else:\n","             print(\"--- Tool Error: GOOGLE_API_KEY not found. Cannot initialize Gemini client. ---\")\n","             client_initialized = False\n","\n","    except Exception as e:\n","        print(f\"--- Tool Error: Failed to initialize Gemini client: {e} ---\")\n","        client_initialized = False\n","        client = None\n","\n","    for i, trip in enumerate(state['trips']):\n","        properties = trip.get('properties', [])\n","        if not properties or not isinstance(properties, list):\n","            print(f\"--- Tool Warning: Trip {i+1} has no properties or properties format incorrect, skipping plan generation. ---\")\n","            trip['map_url'] = \"N/A - No properties listed\"\n","            trip['summary_card'] = {\"error\": \"No properties in this trip\"}\n","            continue\n","\n","        property_list_for_prompt = \"; \".join([\n","            f\"{getattr(p, 'title', 'Property')} at {getattr(p, 'address', 'N/A')}, {getattr(p, 'city', 'N/A')}, {getattr(p, 'state', 'N/A')} \"\n","            f\"({getattr(p, 'bedrooms', 'N/A')} bed, {getattr(p, 'bathrooms', 'N/A')} bath, {getattr(p, 'sqft', 'N/A')} sq ft, \" # Use 'sqft' as per PropertyJson\n","            f\"Price: {getattr(p, 'price_display', 'N/A')} {getattr(p, 'price_type', 'N/A')}, Pets Allowed: {getattr(p, 'pets_allowed', 'N/A')}, \"\n","            f\"Fee: {getattr(p, 'fee', 'N/A')}, Amenities: {getattr(p, 'amenities', 'N/A')})\"\n","            for p in properties\n","            if all([getattr(p, 'address', None), getattr(p, 'city', None), getattr(p, 'state', None)])\n","        ])\n","\n","        if property_list_for_prompt and client_initialized and client is not None:\n","            llm_prompt = f\"\"\"\n","            Please generate a Google Maps URL that displays the locations of the following properties.\n","            Ensure the URL directly shows markers for these locations. Include key details about each property\n","            in the information displayed on the map if possible, or structure the URL to highlight these properties.\n","            Properties:\n","            {property_list_for_prompt}\n","            Provide only the Google Maps URL in your response, starting with 'https://'.\n","            Do not include any other text, explanation, or formatting.\n","            \"\"\"\n","            try:\n","                print(f\"--- Tool: Calling Gemini 2.0 Flash for Map URL for Trip {i+1} ---\")\n","                answer = client.models.generate_content(\n","                    model=\"gemini-2.0-flash\",\n","                    contents=llm_prompt\n","                )\n","                generated_map_url = answer.text.strip()\n","                if generated_map_url.startswith(\"http\") and \"google\" in generated_map_url and \"maps\" in generated_map_url:\n","                     trip['map_url'] = generated_map_url\n","                     print(f\"--- Tool: Gemini generated URL for Trip {i+1}: {trip['map_url']} ---\")\n","                else:\n","                     trip['map_url'] = f\"N/A - LLM did not return a valid URL format: {generated_map_url[:200]}...\"\n","                     print(f\"--- Tool Warning: Gemini did not return a valid URL format for Trip {i+1}. Response snippet: {generated_map_url[:200]} ---\")\n","\n","            except Exception as e:\n","                trip['map_url'] = f\"N/A - Error calling LLM: {e}\"\n","                print(f\"--- Tool Error: Failed to call Gemini for Trip {i+1}: {e} ---\")\n","\n","        elif not property_list_for_prompt:\n","            trip['map_url'] = \"N/A - No valid property details for LLM prompt\"\n","            print(f\"--- Tool Warning: No valid property details for LLM prompt for Trip {i+1}. Map URL set to N/A. ---\")\n","        else:\n","            trip['map_url'] = \"N/A - LLM client not initialized\"\n","            print(f\"--- Tool Warning: LLM client not initialized. Map URL set to N/A for Trip {i+1}. ---\")\n","\n","        prop_details_summary = []\n","        for p in properties:\n","             detail = {\n","                 \"id\": getattr(p, 'id', 'N/A'),\n","                 \"title\": getattr(p, 'title', 'N/A'),\n","                 \"city\": getattr(p, 'city', 'N/A'),\n","                 \"state\": getattr(p, 'state', 'N/A'),\n","                 \"price\": getattr(p, 'price', None),\n","                 \"price_display\": getattr(p, 'price_display', 'N/A'),\n","                 \"price_type\": getattr(p, 'price_type', 'N/A'),\n","                 \"bedrooms\": getattr(p, 'bedrooms', 'N/A'),\n","                 \"bathrooms\": getattr(p, 'bathrooms', 'N/A'),\n","                 \"square_feet\": getattr(p, 'sqft', 'N/A'),\n","                 \"pets_allowed\": getattr(p, 'pets_allowed', 'N/A'),\n","                 \"fee\": getattr(p, 'fee', 'N/A'),\n","                 \"amenities\": getattr(p, 'amenities', 'N/A'),\n","                 \"address\": getattr(p, 'address', 'N/A')\n","             }\n","             prop_details_summary.append(detail)\n","        cities_covered = sorted(list(set(f\"{getattr(p, 'city', '')}, {getattr(p, 'state', '')}\"\n","                                       for p in properties if getattr(p, 'city', None) and getattr(p, 'state', None))))\n","\n","        valid_prices = [p['price'] for p in prop_details_summary if p['price'] is not None and isinstance(p['price'], (int, float))]\n","        total_price_sum = sum(valid_prices) if valid_prices else 0\n","        avg_price = total_price_sum / len(valid_prices) if valid_prices else 0\n","\n","        trip['summary_card'] = {\n","            \"trip_index\": i + 1,\n","            \"number_of_properties\": len(properties),\n","            \"cities_covered\": cities_covered if cities_covered else [\"N/A\"],\n","            \"average_price\": round(avg_price) if avg_price else \"N/A\",\n","            \"total_price_sum\": total_price_sum if total_price_sum else \"N/A\",\n","            \"property_details_preview\": [\n","                {\n","                    \"title\": d['title'],\n","                    \"city\": d['city'],\n","                    \"bedrooms\": d['bedrooms'],\n","                    \"bathrooms\": d['bathrooms'],\n","                    \"price_display\": d['price_display']\n","                } for d in prop_details_summary[:3]\n","            ] + ([{\"...\": \"...\"}] if len(prop_details_summary) > 3 else []),\n","            \"_full_property_details\": prop_details_summary\n","        }\n","\n","        print(f\"--- Tool: Generated Summary Card for Trip {i+1} ---\")\n","    print(f\"--- Tool: Finished generating plans for {len(state.get('trips', []))} trips. ---\")\n","\n","    return state"],"metadata":{"id":"LrU7BL5Abk8q"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Initializing LLM and Defining System Instructions\n","\n","This cell sets up the Language Model (LLM) and defines the system instructions for the real estate agent:\n","\n","- **LLM Initialization**:\n","  - Creates a `ChatGoogleGenerativeAI` instance using the `gemini-2.0-flash` model with a temperature of 0.7 (for balanced creativity) and the `GOOGLE_API_KEY`.\n","  - Logs successful initialization or raises an error if the API key or model is invalid.\n","\n","- **System Instructions (`REAL_ESTATE_AGENT_SYSINT`)**:\n","  - Defines the persona of a \"helpful and knowledgeable real estate AI assistant\" for finding rental properties.\n","  - Outlines the workflow:\n","    - Use `query_properties` to search for properties based on user descriptions.\n","    - Use `add_to_property_set` to save properties to the user’s set, ensuring full metadata is provided.\n","    - Use `remove_from_property_set` to remove properties by index.\n","    - Use `generate_groups_for_visits` to cluster properties into trips, followed by `generate_visit_plan` for maps and summaries.\n","  - Emphasizes conversational guidance, clarity in presenting results, and error handling (e.g., checking for empty sets, avoiding hallucination).\n","  - Lists available tools for reference.\n","\n","- **Tool Setup**:\n","  - Defines a list of tools: `query_properties`, `add_to_property_set`, `remove_from_property_set`, `generate_groups_for_visits`, `generate_visit_plan`.\n","  - Creates a `ToolNode` for executing these tools within the LangGraph workflow.\n","\n","This step prepares the conversational AI component, ensuring it can interact with users and execute tools as needed."],"metadata":{"id":"4mnsaBE_rrNZ"}},{"cell_type":"code","source":["print(\"\\nDefining LangGraph graph...\")\n","\n","try:\n","    llm = ChatGoogleGenerativeAI(\n","        model=\"gemini-2.0-flash\",\n","        temperature=0.7,\n","        google_api_key=GOOGLE_API_KEY,\n","    )\n","    print(\"ChatGoogleGenerativeAI LLM initialized.\")\n","except Exception as e:\n","    print(f\"Error initializing LLM. Ensure API key is correct and model is available. Error: {e}\")\n","    llm = None\n","    raise\n","\n","\n","REAL_ESTATE_AGENT_SYSINT = (\n","    \"You are a helpful and knowledgeable real estate AI assistant. Your goal is to assist users in finding rental properties. \"\n","    \"You have access to a database of property listings.\"\n","    \"You can search for properties using the `query_properties` tool based on user descriptions (e.g., location, number of bedrooms/bathrooms, price range, amenities, pet policy). When presenting results, list them clearly, maybe with indices like [0], [1], etc., mentioning key details like title, price, bedrooms, bathrooms, city, and state.\"\n","    \"When the user finds properties they like from the search results, they might ask you to save them to a 'property set'. Use the `add_to_property_set` tool to add properties. You MUST provide the full property details (as a dictionary, typically obtained from the metadata of the search results) for each property you want to add. You can refer back to the details you presented from `query_properties` results to construct these dictionaries.\"\n","    \"The user can ask you to remove properties from their current 'property set' by referring to their 0-based index within the set. Use the `remove_from_property_set` tool for this, providing the list of indices to remove.\"\n","    \"Once the user has a set of properties, they might want to plan visits. Use the `generate_groups_for_visits` tool FIRST to cluster the properties in the set into logical groups (trips) based on location. You need to specify the desired number of trips (e.g., if the user says 'organize them into 3 trips', call the tool with n_trips=3).\"\n","    \"AFTER successfully grouping the properties, use the `generate_visit_plan` tool SECOND to generate summary cards and map links for these trip groups.\"\n","    \"When the property set or trips are modified, clearly inform the user about the changes and the current state (e.g., 'Added 3 properties, your set now has 5.', 'Organized your 10 properties into 3 visit groups.').\"\n","    \"Be conversational, friendly, and guide the user. Ask clarifying questions if the request is unclear (e.g., 'What city or area are you interested in?').\"\n","    \"Always check if the property set is empty before attempting to remove or group items. Remember that indices for removing items refer to the CURRENT property set list.\"\n","    \"Do not hallucinate property details or make up map URLs; only use information from tool outputs.\"\n","    \"Available tools: `query_properties`, `add_to_property_set`, `remove_from_property_set`, `generate_groups_for_visits`, `generate_visit_plan`.\"\n","    \"You are in an interactive chat. Respond to the user based on the conversation history and tool results.\"\n",")\n","\n","\n","tools = [query_properties, add_to_property_set, remove_from_property_set, generate_groups_for_visits, generate_visit_plan]\n","tool_node = ToolNode(tools)"],"metadata":{"id":"GUrESy9VgZAH"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Defining Agent Node and Routing Logic\n","\n","This cell defines the core logic for the LangGraph agent and its decision-making process:\n","\n","- **Agent Node (`agent_node`)**:\n","  - Invokes the LLM (`ChatGoogleGenerativeAI`) to process user input and decide the next action.\n","  - Constructs a message list with the system instructions (`REAL_ESTATE_AGENT_SYSINT`) and the conversation history (`state['messages']`).\n","  - Handles LLM invocation errors by returning an error message as an `AIMessage`.\n","  - Returns the updated state with the LLM’s response added to `messages`.\n","\n","- **Routing Logic (`should_continue`)**:\n","  - Determines the next step based on the last message in the state:\n","    - If a `ToolMessage`, routes back to the `agent` (tool execution complete).\n","    - If an `AIMessage` with `tool_calls`, routes to `tools` for execution.\n","    - If an `AIMessage` without `tool_calls`, ends the turn (`__end__`).\n","    - For other message types, routes to `agent` for further processing.\n","  - Logs routing decisions for debugging (e.g., number of tool calls, message types).\n","\n","This logic ensures the agent can handle user inputs, execute tools, and manage the conversation flow appropriately."],"metadata":{"id":"Z102ekHBrrNZ"}},{"cell_type":"code","source":["def agent_node(state: Pstate):\n","    \"\"\"Invokes the LLM to get the next action or response.\"\"\"\n","    print(\"--- Agent Node: Invoking LLM ---\")\n","    if llm is None:\n","        error_msg = AIMessage(content=\"Error: LLM not initialized. Cannot process request.\")\n","        return {\"messages\": [error_msg]}\n","    messages_for_llm = [SystemMessage(content=REAL_ESTATE_AGENT_SYSINT)] + state['messages']\n","\n","\n","    try:\n","        response = llm.invoke(messages_for_llm)\n","        print(f\"--- Agent Node: LLM Response received (type: {type(response).__name__}) ---\")\n","        return {\"messages\": [response]}\n","    except Exception as e:\n","         print(f\"--- Agent Node Error during LLM invocation: {e} ---\")\n","         error_message = AIMessage(content=f\"An error occurred while processing your request: {e}\")\n","         return {\"messages\": [error_message]}\n","\n","\n","\n","def should_continue(state: Pstate) -> Literal[\"tools\", \"__end__\", \"agent\"]:\n","    \"\"\"Determines whether to call tools, end the current execution step, or return to agent.\"\"\"\n","    last_message = state['messages'][-1]\n","\n","    if isinstance(last_message, ToolMessage):\n","         print(f\"--- Conditional Edge: Last message is ToolMessage. Routing back to agent. ---\")\n","         return \"agent\"\n","\n","    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n","        if isinstance(last_message.tool_calls, list) and len(last_message.tool_calls) > 0:\n","             print(f\"--- Conditional Edge: AI message has tool_calls. Routing to tools ({len(last_message.tool_calls)} calls) ---\")\n","             return \"tools\"\n","        else:\n","             print(f\"--- Conditional Edge: AI message has invalid tool_calls format or is empty. Ending the turn. ---\")\n","             return END\n","\n","    if isinstance(last_message, AIMessage) and not last_message.tool_calls:\n","        print(\"--- Conditional Edge: AI message has no tool calls. Ending the turn. ---\")\n","        return END\n","\n","    print(f\"--- Conditional Edge: Last message is {type(last_message).__name__}. Routing to agent. ---\")\n","    return \"agent\""],"metadata":{"id":"NW-coi5Lg0wx"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Building and Compiling the LangGraph Workflow\n","\n","This cell constructs and compiles the LangGraph workflow for the real estate assistant:\n","\n","- **Graph Construction**:\n","  - Creates a `StateGraph` with the `Pstate` type to manage the workflow state.\n","  - Adds two nodes:\n","    - `agent`: Executes the `agent_node` function to invoke the LLM.\n","    - `tools`: Executes the `tool_node` to run tools like `query_properties`.\n","  - Sets the entry point to the `agent` node.\n","  - Adds conditional edges from `agent` using `should_continue` to route to `tools`, `agent`, or `END`.\n","  - Adds a direct edge from `tools` back to `agent` to process tool outputs.\n","\n","- **Compilation**:\n","  - Compiles the graph into an executable workflow using `graph_builder.compile()`.\n","  - Logs successful compilation or exits on error.\n","\n","This step finalizes the workflow, enabling the assistant to handle user inputs, execute tools, and manage state transitions."],"metadata":{"id":"D4fw3sCrrrNZ"}},{"cell_type":"code","source":["graph_builder = StateGraph(Pstate)\n","\n","graph_builder.add_node(\"agent\", agent_node)\n","graph_builder.add_node(\"tools\", tool_node)\n","graph_builder.set_entry_point(\"agent\")\n","\n","graph_builder.add_conditional_edges(\n","    \"agent\",\n","    should_continue,\n","    {\n","        \"tools\": \"tools\",\n","        END: END,\n","        \"agent\": \"agent\"\n","    }\n",")\n","\n","\n","graph_builder.add_edge(\"tools\", \"agent\")\n","\n","\n","print(\"Compiling graph...\")\n","try:\n","    compiled_graph = graph_builder.compile()\n","    print(\"Graph compiled successfully.\")\n","except Exception as e:\n","    print(f\"Error compiling graph: {e}\")\n","    exit()"],"metadata":{"id":"lBUz2TNohKqm"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Running the Interactive Chat Session\n","\n","This cell implements an interactive chat loop for the real estate assistant:\n","\n","- **Initialization**:\n","  - Initializes the state (`current_state`) with empty `messages`, `property_set`, and `trips`.\n","  - Displays a welcome message and instructions to type 'quit' to exit.\n","\n","- **Chat Loop**:\n","  - Prompts the user for input.\n","  - Exits if the input is 'quit', 'q', 'bye', or 'goodbye' (case-insensitive).\n","  - Appends the user’s input as a `HumanMessage` to the state’s `messages`.\n","  - Invokes the compiled LangGraph workflow (`compiled_graph.invoke`) to process the input and update the state.\n","  - Prints the last message from the updated state (typically an `AIMessage` with the assistant’s response).\n","  - Handles errors by appending an error message to the state and continuing the loop.\n","  - Logs each step for debugging (e.g., graph invocation, message types).\n","\n","- **Conversation Example** (from output):\n","  - User searches for 2-bedroom apartments in Chicago ($1000-$2000, with gym).\n","  - Assistant presents three properties, adds them to the property set, removes one, organizes the remaining two into one trip, and generates a summary card.\n","  - The assistant uses pseudo-tool calls (e.g., `tool_code` in responses) but does not execute them due to a potential issue with tool integration (see below).\n","\n","- **Issues Noted**:\n","  - The assistant outputs tool calls as code blocks (e.g., `query_properties(...)`) but does not execute them, indicating a possible misconfiguration in the LangGraph setup or LLM tool-calling behavior.\n","  - Properties in the conversation (e.g., \"Luxury 2 bed 2 bath in Streeterville!\") appear to be fabricated, as they don’t match the dataset’s actual listings (e.g., from the ChromaDB test query).\n","  - Validation errors likely occur when adding properties due to missing `id` fields in the fabricated data.\n","\n","This cell demonstrates the assistant’s conversational capabilities but highlights areas for improvement in tool execution and data consistency."],"metadata":{"id":"l_W2HSJIrrNZ"}},{"cell_type":"code","source":["print(\"\\n--- Starting the interactive LangGraph session ---\")\n","print(\"\\n---WELCOME TO RENT ASSISTANT - YOUR RENTAL BUDDY\")\n","print(\"Type 'quit' to end the conversation.\")\n","print(\"-\" * 30)\n","\n","\n","current_state: Pstate = {\n","    \"messages\": [],\n","    \"property_set\": [],\n","    \"trips\": []\n","}\n","\n","\n","while True:\n","    user_input = input(\"You: \")\n","\n","    if user_input.lower() == 'quit' or user_input.lower()=='q' or user_input.lower()=='bye' or user_input.lower()=='goodbye':\n","        print(\"--- Ending conversation ---\")\n","        break\n","\n","    current_state['messages'].append(HumanMessage(content=user_input))\n","    print(\"--- Invoking graph for one turn ---\")\n","    try:\n","        new_state = compiled_graph.invoke(current_state)\n","        current_state = new_state\n","\n","        if current_state and 'messages' in current_state and current_state['messages']:\n","            last_message = current_state['messages'][-1]\n","\n","            if isinstance(last_message, AIMessage):\n","                if last_message.content:\n","                    print(f\"AI: {last_message.content}\")\n","\n","            elif isinstance(last_message, HumanMessage):\n","                 print(\"AI (Unexpected - received HumanMessage as final output)\")\n","            elif isinstance(last_message, ToolMessage):\n","                 print(\"AI (Tool Response received directly)\")\n","\n","            else:\n","                 print(f\"AI (Unexpected message type: {type(last_message).__name__})\")\n","\n","\n","    except Exception as e:\n","        print(f\"\\n--- An unexpected error occurred during graph execution turn: {e} ---\")\n","        error_msg = AIMessage(content=f\"An internal error occurred: {e}. Please try again or rephrase your request.\")\n","        if 'messages' in current_state and isinstance(current_state['messages'], list):\n","             current_state['messages'].append(error_msg)\n","        else:\n","             print(\"--- Error: State messages list is missing or corrupted. Cannot add error message. ---\")\n","\n","    print(\"-\" * 30)\n","\n","print(\"\\n--- Interactive session finished ---\")"],"metadata":{"id":"DbdVaqWehYpG"},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"id":"r8A35NaxitBt"},"outputs":[],"execution_count":null}]}